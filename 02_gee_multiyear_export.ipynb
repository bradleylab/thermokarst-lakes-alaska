{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Year Lake Ice Phenology Data Export\n",
    "## Part 2: GEE Processing and Export (2019-2021)\n",
    "\n",
    "**Goal:** Export S1 + S2 + ERA5 data for North Slope lakes across 3 years\n",
    "\n",
    "**Strategy:**\n",
    "- Process chunks independently (spatial parallelization)\n",
    "- Export one year at a time per chunk\n",
    "- Use efficient spatial filtering (only process S2 images that overlap lakes)\n",
    "- Total exports: ~19 chunks × 3 years = ~57 exports\n",
    "\n",
    "**Data sources:**\n",
    "- Sentinel-1 GRD (SAR)\n",
    "- Sentinel-2 SR Harmonized (optical, for NDSI)\n",
    "- ERA5-Land (temperature)\n",
    "\n",
    "**Years:** 2019, 2020, 2021 (match ALPOD temporal coverage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/gee/lib/python3.10/site-packages/google/api_core/_python_version_support.py:266: FutureWarning: You are using a Python version (3.10.19) which Google will stop supporting in new releases of google.api_core once it reaches its end of life (2026-10-04). Please upgrade to the latest Python version, or at least Python 3.11, to continue receiving updates for google.api_core past that date.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "httplib2 transport does not support per-request timeout. Set the timeout when constructing the httplib2.Http instance.\n",
      "httplib2 transport does not support per-request timeout. Set the timeout when constructing the httplib2.Http instance.\n",
      "httplib2 transport does not support per-request timeout. Set the timeout when constructing the httplib2.Http instance.\n",
      "httplib2 transport does not support per-request timeout. Set the timeout when constructing the httplib2.Http instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports successful!\n",
      "Earth Engine initialized: GEE Initialized\n"
     ]
    }
   ],
   "source": [
    "import ee\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Initialize Earth Engine\n",
    "ee.Initialize()\n",
    "\n",
    "print(\"Imports successful!\")\n",
    "print(f\"Earth Engine initialized: {ee.String('GEE Initialized').getInfo()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  Years: [2019, 2020, 2021]\n",
      "  Chunks path: gs://wustl-eeps-geospatial/thermokarst_lakes/processed/chunks\n",
      "  Output: gs://wustl-eeps-geospatial/thermokarst_lakes/exports\n",
      "  S2 scene cloud threshold: 30%\n",
      "  S2 pixel cloud probability threshold: 40%\n",
      "  S2 time window: ±3 days\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "BUCKET = 'wustl-eeps-geospatial'\n",
    "BASE_PATH = 'thermokarst_lakes'\n",
    "CHUNKS_PATH = f'gs://{BUCKET}/{BASE_PATH}/processed/chunks'\n",
    "OUTPUT_PATH = f'{BASE_PATH}/exports'  # No gs:// prefix for GEE exports\n",
    "\n",
    "# Years to process (match ALPOD coverage)\n",
    "YEARS = [2019, 2020, 2021]\n",
    "\n",
    "# Processing parameters\n",
    "SCALE = 10  # Sentinel-1 resolution\n",
    "S2_CLOUD_THRESHOLD = 30  # Maximum cloud cover for S2 images (scene-level)\n",
    "S2_CLOUD_PROB_THRESHOLD = 40  # s2cloudless probability threshold (pixel-level)\n",
    "S2_TIME_WINDOW = 3  # Days before/after S1 acquisition to look for S2\n",
    "\n",
    "# Projection\n",
    "ALASKA_ALBERS = 'EPSG:3338'\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Years: {YEARS}\")\n",
    "print(f\"  Chunks path: {CHUNKS_PATH}\")\n",
    "print(f\"  Output: gs://{BUCKET}/{OUTPUT_PATH}\")\n",
    "print(f\"  S2 scene cloud threshold: {S2_CLOUD_THRESHOLD}%\")\n",
    "print(f\"  S2 pixel cloud probability threshold: {S2_CLOUD_PROB_THRESHOLD}%\")\n",
    "print(f\"  S2 time window: ±{S2_TIME_WINDOW} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chunk_from_bucket(chunk_id):\n",
    "    \"\"\"\n",
    "    Load a chunk GeoJSON from bucket and convert to ee.FeatureCollection\n",
    "    Downloads to local temp file first to avoid GCS streaming issues\n",
    "    \"\"\"\n",
    "    import os\n",
    "    \n",
    "    chunk_file = f'{CHUNKS_PATH}/chunk_{chunk_id:02d}.geojson'\n",
    "    \n",
    "    # Download to local temp file\n",
    "    local_path = f'/tmp/chunk_{chunk_id:02d}.geojson'\n",
    "    \n",
    "    # Use gsutil to download (reliable in Vertex AI)\n",
    "    os.system(f'gsutil -q cp {chunk_file} {local_path}')\n",
    "    \n",
    "    # Load from local file\n",
    "    gdf = gpd.read_file(local_path)\n",
    "    \n",
    "    print(f\"  Loaded chunk {chunk_id}: {len(gdf)} lakes\")\n",
    "    print(f\"    Bounds: {gdf.total_bounds}\")\n",
    "    \n",
    "    # Keep only essential properties to reduce payload size\n",
    "    essential_cols = ['geometry']\n",
    "    \n",
    "    if 'lake_area_km2' in gdf.columns:\n",
    "        essential_cols.append('lake_area_km2')\n",
    "    \n",
    "    # Create simple ID if needed\n",
    "    gdf['lake_id'] = range(len(gdf))\n",
    "    essential_cols.append('lake_id')\n",
    "    \n",
    "    gdf_simplified = gdf[essential_cols].copy()\n",
    "    \n",
    "    # Simplify geometries to reduce size (5m tolerance)\n",
    "    print(f\"  Simplifying geometries...\")\n",
    "    gdf_simplified['geometry'] = gdf_simplified.geometry.simplify(\n",
    "        tolerance=5, preserve_topology=True\n",
    "    )\n",
    "    \n",
    "    # Convert to GeoJSON dict\n",
    "    geojson = gdf_simplified.__geo_interface__\n",
    "    \n",
    "    print(f\"  Creating EE FeatureCollection...\")\n",
    "    fc = ee.FeatureCollection(geojson)\n",
    "    print(f\"  FeatureCollection created successfully\")\n",
    "    \n",
    "    return fc, gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lake_geometry_metrics(fc, chunk_bounds):\n",
    "    \"\"\"\n",
    "    Add buffered interior and landscape ring geometries\n",
    "    Masks ALL ALPOD lakes from landscape ring (not just processed lakes)\n",
    "    \n",
    "    Args:\n",
    "        fc: FeatureCollection of lakes to process (>0.05 km²)\n",
    "        chunk_bounds: ee.Geometry.Rectangle defining the spatial extent\n",
    "    \"\"\"\n",
    "    print(\"  Loading full ALPOD dataset for landscape masking...\")\n",
    "    \n",
    "    # Download all shapefile components locally\n",
    "    import os\n",
    "    os.system('gsutil -q cp gs://wustl-eeps-geospatial/thermokarst_lakes/ALPODlakes/ALPODlakes.shp /tmp/')\n",
    "    os.system('gsutil -q cp gs://wustl-eeps-geospatial/thermokarst_lakes/ALPODlakes/ALPODlakes.shx /tmp/')\n",
    "    os.system('gsutil -q cp gs://wustl-eeps-geospatial/thermokarst_lakes/ALPODlakes/ALPODlakes.dbf /tmp/')\n",
    "    os.system('gsutil -q cp gs://wustl-eeps-geospatial/thermokarst_lakes/ALPODlakes/ALPODlakes.prj /tmp/')\n",
    "    os.system('gsutil -q cp gs://wustl-eeps-geospatial/thermokarst_lakes/ALPODlakes/ALPODlakes.cpg /tmp/ 2>/dev/null')\n",
    "    \n",
    "    local_alpod = '/tmp/ALPODlakes.shp'\n",
    "    \n",
    "    # Load with geopandas\n",
    "    import geopandas as gpd\n",
    "    all_alpod = gpd.read_file(local_alpod)\n",
    "    \n",
    "    # Get bounding box from chunk_bounds\n",
    "    bounds_coords = chunk_bounds.bounds().getInfo()['coordinates'][0]\n",
    "    minx = min(c[0] for c in bounds_coords) - 0.01\n",
    "    maxx = max(c[0] for c in bounds_coords) + 0.01\n",
    "    miny = min(c[1] for c in bounds_coords) - 0.01\n",
    "    maxy = max(c[1] for c in bounds_coords) + 0.01\n",
    "    \n",
    "    # Filter ALPOD to chunk region (including small lakes)\n",
    "    nearby_lakes = all_alpod.cx[minx:maxx, miny:maxy]\n",
    "    \n",
    "    print(f\"    Found {len(nearby_lakes)} total lakes in chunk region (all sizes)\")\n",
    "    \n",
    "    # Simplify slightly to reduce payload\n",
    "    nearby_lakes_simple = nearby_lakes.copy()\n",
    "    nearby_lakes_simple['geometry'] = nearby_lakes_simple.geometry.simplify(\n",
    "        tolerance=5, preserve_topology=True\n",
    "    )\n",
    "    \n",
    "    # Convert to EE FeatureCollection\n",
    "    all_lakes_geojson = nearby_lakes_simple[['geometry']].__geo_interface__\n",
    "    all_lakes_ee = ee.FeatureCollection(all_lakes_geojson)\n",
    "    \n",
    "    # PRE-COMPUTE: Union of ALL lake geometries (including small ones)\n",
    "    all_lakes_union = all_lakes_ee.geometry().dissolve()\n",
    "    \n",
    "    print(\"  Creating lake interior buffers and landscape rings...\")\n",
    "    \n",
    "    def buffer_interior(feat):\n",
    "        geom = feat.geometry()\n",
    "        area = geom.area()\n",
    "        \n",
    "        buffered = geom.buffer(-10)\n",
    "        buffered = ee.Algorithms.If(\n",
    "            area.lt(10000),\n",
    "            geom,\n",
    "            buffered\n",
    "        )\n",
    "        \n",
    "        return feat.set({'lake_interior': buffered})\n",
    "    \n",
    "    def add_landscape_ring(feat):\n",
    "        geom = feat.geometry()\n",
    "        \n",
    "        # Create 100m ring\n",
    "        outer = geom.buffer(100)\n",
    "        ring = outer.difference(geom)\n",
    "        \n",
    "        # Remove ALL lakes from ring (big AND small)\n",
    "        clean_ring = ring.difference(all_lakes_union)\n",
    "        \n",
    "        return feat.set({'landscape_ring': ring})\n",
    "    \n",
    "    fc_with_interior = fc.map(buffer_interior)\n",
    "    fc_with_landscape = fc_with_interior.map(add_landscape_ring)\n",
    "    \n",
    "    return fc_with_landscape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Sentinel-1 Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sentinel1(lakes_fc, year, region_bounds):\n",
    "    \"\"\"\n",
    "    Process Sentinel-1 SAR data for a given year and region\n",
    "    \"\"\"\n",
    "    # Filter S1 collection\n",
    "    s1 = (ee.ImageCollection('COPERNICUS/S1_GRD')\n",
    "          .filterDate(f'{year}-01-01', f'{year}-12-31')\n",
    "          .filterBounds(region_bounds)\n",
    "          .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV'))\n",
    "          .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH'))\n",
    "          .filter(ee.Filter.eq('instrumentMode', 'IW'))\n",
    "          .filter(ee.Filter.eq('orbitProperties_pass', 'DESCENDING'))\n",
    "          .select(['VV', 'VH']))\n",
    "    \n",
    "    def extract_s1_features(img):\n",
    "        \"\"\"\n",
    "        Extract S1 backscatter for each lake\n",
    "        \"\"\"\n",
    "        date = img.date()\n",
    "        \n",
    "        def lake_s1_stats(lake):\n",
    "            # Get lake interior geometry\n",
    "            lake_geom = ee.Geometry(lake.get('lake_interior'))\n",
    "            \n",
    "            # Extract VV and VH\n",
    "            stats = img.reduceRegion(\n",
    "                reducer=ee.Reducer.mean(),\n",
    "                geometry=lake_geom,\n",
    "                scale=SCALE,\n",
    "                maxPixels=1e9\n",
    "            )\n",
    "            \n",
    "            return lake.set({\n",
    "                's1_date': date.format('YYYY-MM-dd'),\n",
    "                's1_doy': date.getRelative('day', 'year'),\n",
    "                'vv_db': stats.get('VV'),\n",
    "                'vh_db': stats.get('VH')\n",
    "            })\n",
    "        \n",
    "        return lakes_fc.map(lake_s1_stats)\n",
    "    \n",
    "    # Process all S1 images\n",
    "    s1_features = s1.map(extract_s1_features).flatten()\n",
    "    \n",
    "    return s1_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Sentinel-2 Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ndsi(img):\n",
    "    \"\"\"\n",
    "    Compute Normalized Difference Snow Index (NDSI)\n",
    "    NDSI = (Green - SWIR1) / (Green + SWIR1)\n",
    "    \"\"\"\n",
    "    green = img.select('B3')\n",
    "    swir1 = img.select('B11')\n",
    "    \n",
    "    ndsi = green.subtract(swir1).divide(green.add(swir1)).rename('ndsi')\n",
    "    \n",
    "    return img.addBands(ndsi)\n",
    "\n",
    "def mask_s2_clouds(img):\n",
    "    \"\"\"\n",
    "    Mask clouds using QA60 band (basic cloud mask)\n",
    "    \"\"\"\n",
    "    qa = img.select('QA60')\n",
    "    \n",
    "    # Bits 10 and 11 are clouds and cirrus\n",
    "    cloud_bit_mask = 1 << 10\n",
    "    cirrus_bit_mask = 1 << 11\n",
    "    \n",
    "    # Both should be zero (clear conditions)\n",
    "    mask = qa.bitwiseAnd(cloud_bit_mask).eq(0).And(\n",
    "           qa.bitwiseAnd(cirrus_bit_mask).eq(0))\n",
    "    \n",
    "    return img.updateMask(mask)\n",
    "\n",
    "def add_s2cloudless_mask(img):\n",
    "    \"\"\"\n",
    "    Add s2cloudless probability-based cloud mask\n",
    "    More accurate than QA60, especially for distinguishing ice from clouds\n",
    "    \"\"\"\n",
    "    # Get the s2cloudless collection\n",
    "    s2_cloudless = ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY')\n",
    "    \n",
    "    # Find the matching cloud probability image\n",
    "    # Match by system:index (unique ID that links S2 and s2cloudless)\n",
    "    cloud_prob = (s2_cloudless\n",
    "                  .filter(ee.Filter.eq('system:index', img.get('system:index')))\n",
    "                  .first()\n",
    "                  .select('probability'))\n",
    "    \n",
    "    # Mask pixels with cloud probability > threshold\n",
    "    is_clear = cloud_prob.lt(S2_CLOUD_PROB_THRESHOLD)\n",
    "    \n",
    "    return img.updateMask(is_clear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sentinel2(lakes_fc, year, region_bounds):\n",
    "    \"\"\"\n",
    "    Process Sentinel-2 optical data for ice detection\n",
    "    Uses both QA60 and s2cloudless for robust cloud masking\n",
    "    Handles bad images gracefully\n",
    "    \"\"\"\n",
    "    # Get S2 collection for the year\n",
    "    s2 = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
    "          .filterDate(f'{year}-01-01', f'{year}-12-31')\n",
    "          .filterBounds(region_bounds)\n",
    "          .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', S2_CLOUD_THRESHOLD))\n",
    "          .map(mask_s2_clouds)\n",
    "          .map(add_s2cloudless_mask)\n",
    "          .map(compute_ndsi))\n",
    "    \n",
    "    def extract_s2_for_date(s2_img):\n",
    "        s2_date = s2_img.date()\n",
    "        s2_bounds = s2_img.geometry()\n",
    "        cloud_pct = s2_img.get('CLOUDY_PIXEL_PERCENTAGE')\n",
    "        \n",
    "        # Only process lakes that overlap this S2 image\n",
    "        lakes_in_image = lakes_fc.filterBounds(s2_bounds)\n",
    "        \n",
    "        def lake_s2_stats(lake):\n",
    "            lake_geom = ee.Geometry(lake.get('lake_interior'))\n",
    "            \n",
    "            # Compute ice fraction (NDSI > 0.4)\n",
    "            ndsi = s2_img.select('ndsi')\n",
    "            ice_mask = ndsi.gt(0.4)\n",
    "            \n",
    "            stats = ice_mask.reduceRegion(\n",
    "                reducer=ee.Reducer.mean(),\n",
    "                geometry=lake_geom,\n",
    "                scale=20,\n",
    "                maxPixels=1e9\n",
    "            )\n",
    "            \n",
    "            ice_fraction = stats.get('ndsi')\n",
    "            \n",
    "            return lake.set({\n",
    "                's2_date': s2_date.format('YYYY-MM-dd'),\n",
    "                's2_doy': s2_date.getRelative('day', 'year'),\n",
    "                's2_ice_fraction': ice_fraction,\n",
    "                's2_cloud_pct': cloud_pct\n",
    "            })\n",
    "        \n",
    "        return lakes_in_image.map(lake_s2_stats)\n",
    "    \n",
    "    # Process all S2 images\n",
    "    s2_features = s2.map(extract_s2_for_date).flatten()\n",
    "    \n",
    "    return s2_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ERA5 Temperature Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_era5_temperature(lakes_fc, year):\n",
    "    \"\"\"\n",
    "    Process ERA5-Land temperature data - OPTIMIZED VERSION\n",
    "    Pre-computes daily means once, then samples all lakes in batch\n",
    "    Much faster than computing daily mean separately for each lake\n",
    "    \"\"\"\n",
    "    print(f\"  Loading ERA5 hourly data for {year}...\")\n",
    "    \n",
    "    # Load ERA5-Land hourly data\n",
    "    era5_hourly = (ee.ImageCollection('ECMWF/ERA5_LAND/HOURLY')\n",
    "                   .filterDate(f'{year}-01-01', f'{year}-12-31')\n",
    "                   .select('temperature_2m'))\n",
    "    \n",
    "    # Convert to Celsius\n",
    "    def to_celsius(img):\n",
    "        temp_c = img.subtract(273.15).rename('temp_c')\n",
    "        return temp_c.copyProperties(img, ['system:time_start'])\n",
    "    \n",
    "    era5_hourly = era5_hourly.map(to_celsius)\n",
    "    \n",
    "    print(f\"  Pre-computing daily means...\")\n",
    "    \n",
    "    # Determine number of days in year (handle leap years)\n",
    "    is_leap = ee.Number(year).mod(4).eq(0).And(\n",
    "        ee.Number(year).mod(100).neq(0).Or(\n",
    "            ee.Number(year).mod(400).eq(0)\n",
    "        )\n",
    "    )\n",
    "    n_days = ee.Number(ee.Algorithms.If(is_leap, 366, 365))\n",
    "    \n",
    "    # Pre-compute daily means for entire year (365 or 366 images)\n",
    "    def compute_daily_mean(day):\n",
    "        day = ee.Number(day)\n",
    "        date = ee.Date.fromYMD(year, 1, 1).advance(day.subtract(1), 'day')\n",
    "        next_date = date.advance(1, 'day')\n",
    "        \n",
    "        # Get all hourly images for this day\n",
    "        daily_collection = era5_hourly.filterDate(date, next_date)\n",
    "        \n",
    "        # Check if we have data\n",
    "        has_data = daily_collection.size().gt(0)\n",
    "        \n",
    "        # Compute mean if data exists, otherwise use missing flag\n",
    "        daily_mean = ee.Image(ee.Algorithms.If(\n",
    "            has_data,\n",
    "            daily_collection.mean(),\n",
    "            ee.Image.constant(-9999).rename('temp_c')\n",
    "        ))\n",
    "        \n",
    "        return daily_mean.set({\n",
    "            'system:time_start': date.millis(),\n",
    "            'doy': day,\n",
    "            'date': date.format('YYYY-MM-dd')\n",
    "        })\n",
    "    \n",
    "    days = ee.List.sequence(1, n_days)\n",
    "    era5_daily = ee.ImageCollection.fromImages(days.map(compute_daily_mean))\n",
    "    \n",
    "    print(f\"  Sampling all lakes from daily means...\")\n",
    "    \n",
    "    # Now sample ALL lakes from each daily mean (batch operation)\n",
    "    def sample_all_lakes(daily_img):\n",
    "        doy = daily_img.get('doy')\n",
    "        date = daily_img.get('date')\n",
    "        \n",
    "        # Sample ALL lakes at once using reduceRegions\n",
    "        samples = daily_img.reduceRegions(\n",
    "            collection=lakes_fc,\n",
    "            reducer=ee.Reducer.first(),  # Get pixel value at centroid\n",
    "            scale=11000  # ERA5-Land resolution\n",
    "        )\n",
    "        \n",
    "        # Add date info to each sampled feature\n",
    "        def add_date_info(feat):\n",
    "            # Get the temperature value (from 'first' property created by reducer)\n",
    "            # Use ee.Algorithms.If to provide default if missing\n",
    "            temp_value = ee.Algorithms.If(\n",
    "                feat.propertyNames().contains('first'),\n",
    "                feat.get('first'),\n",
    "                -9999\n",
    "            )\n",
    "            \n",
    "            return feat.set({\n",
    "                'era5_date': date,\n",
    "                'era5_doy': doy,\n",
    "                'temp_c': temp_value\n",
    "            })\n",
    "        \n",
    "        return samples.map(add_date_info)\n",
    "    \n",
    "    # Process all daily images\n",
    "    era5_features = era5_daily.map(sample_all_lakes).flatten()\n",
    "    \n",
    "    return era5_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Export Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_chunk_year(chunk_id, year, lakes_fc, region_bounds):\n",
    "    \"\"\"\n",
    "    Process and export all data for one chunk and one year\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing Chunk {chunk_id}, Year {year}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Add lake geometries\n",
    "    lakes_with_geom = add_lake_geometry_metrics(lakes_fc, region_bounds)\n",
    "    print(\"Lakes processed with geometries\")\n",
    "    \n",
    "    # Process S1\n",
    "    print(\"\\nProcessing Sentinel-1...\")\n",
    "    s1_features = process_sentinel1(lakes_with_geom, year, region_bounds)\n",
    "    print(\"  S1 processing complete\")\n",
    "    \n",
    "    # Process S2\n",
    "    print(\"\\nProcessing Sentinel-2...\")\n",
    "    s2_features = process_sentinel2(lakes_with_geom, year, region_bounds)\n",
    "    print(\"  S2 processing complete\")\n",
    "    \n",
    "    # Process ERA5\n",
    "    print(\"\\nProcessing ERA5 temperature...\")\n",
    "    era5_features = process_era5_temperature(lakes_with_geom, year)\n",
    "    print(\"  ERA5 processing complete\")\n",
    "    \n",
    "    # Export each dataset separately\n",
    "    exports = []\n",
    "    \n",
    "    # S1 export\n",
    "    s1_task = ee.batch.Export.table.toCloudStorage(\n",
    "        collection=s1_features,\n",
    "        description=f'S1_chunk{chunk_id:02d}_{year}',\n",
    "        bucket=BUCKET,\n",
    "        fileNamePrefix=f'{OUTPUT_PATH}/{year}/chunk_{chunk_id:02d}/s1_data',\n",
    "        fileFormat='CSV'\n",
    "    )\n",
    "    \n",
    "    # S2 export\n",
    "    s2_task = ee.batch.Export.table.toCloudStorage(\n",
    "        collection=s2_features,\n",
    "        description=f'S2_chunk{chunk_id:02d}_{year}',\n",
    "        bucket=BUCKET,\n",
    "        fileNamePrefix=f'{OUTPUT_PATH}/{year}/chunk_{chunk_id:02d}/s2_data',\n",
    "        fileFormat='CSV'\n",
    "    )\n",
    "    \n",
    "    # ERA5 export\n",
    "    era5_task = ee.batch.Export.table.toCloudStorage(\n",
    "        collection=era5_features,\n",
    "        description=f'ERA5_chunk{chunk_id:02d}_{year}',\n",
    "        bucket=BUCKET,\n",
    "        fileNamePrefix=f'{OUTPUT_PATH}/{year}/chunk_{chunk_id:02d}/era5_data',\n",
    "        fileFormat='CSV'\n",
    "    )\n",
    "    \n",
    "    exports = [\n",
    "        {'task': s1_task, 'type': 'S1', 'count': 'N/A'},\n",
    "        {'task': s2_task, 'type': 'S2', 'count': 'N/A'},\n",
    "        {'task': era5_task, 'type': 'ERA5', 'count': 'N/A'}\n",
    "    ]\n",
    "    \n",
    "    return exports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Main Export Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks to process: 13\n",
      "Years to process: [2019, 2020, 2021]\n",
      "Total exports: 117 (chunks × years × 3 datasets)\n",
      "\n",
      "Chunk statistics:\n",
      "    chunk_id  n_lakes    lat_min    lat_max     lon_min     lon_max\n",
      "0          0     2083  69.160813  70.902079 -153.130795 -151.727647\n",
      "1          1     1452  69.006262  70.827977 -159.368810 -157.856992\n",
      "2          2     1327  69.040671  70.501113 -150.347535 -148.888885\n",
      "3          3     2518  69.006075  71.117631 -155.556146 -154.195153\n",
      "4          4      780  69.027426  70.294397 -163.578774 -160.999169\n",
      "5          5      223  69.061209  70.121377 -144.849551 -141.047786\n",
      "6          6     1987  69.022434  71.334582 -157.932951 -156.619012\n",
      "7          7      910  69.000834  70.388435 -149.010972 -147.408194\n",
      "8          8     2044  69.016535  70.903127 -154.464362 -153.026821\n",
      "9          9     1383  69.000146  70.478816 -151.904233 -150.237160\n",
      "10        10      903  69.021021  70.839688 -161.140899 -159.325726\n",
      "11        11     2148  69.298632  71.360948 -156.626150 -155.381872\n",
      "12        12      452  69.036249  70.184548 -147.406392 -145.008440\n"
     ]
    }
   ],
   "source": [
    "# Load chunk statistics to know how many chunks we have\n",
    "chunk_stats = pd.read_csv(f'gs://{BUCKET}/{BASE_PATH}/processed/chunk_statistics.csv')\n",
    "n_chunks = len(chunk_stats)\n",
    "\n",
    "print(f\"Total chunks to process: {n_chunks}\")\n",
    "print(f\"Years to process: {YEARS}\")\n",
    "print(f\"Total exports: {n_chunks * len(YEARS) * 3} (chunks × years × 3 datasets)\")\n",
    "print(\"\\nChunk statistics:\")\n",
    "print(chunk_stats[['chunk_id', 'n_lakes', 'lat_min', 'lat_max', 'lon_min', 'lon_max']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################################################\n",
      "TEST RUN: Chunk 0, Year 2019\n",
      "############################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR 1: PROJ: proj_create_from_database: Open of /opt/conda/envs/gee/share/proj failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded chunk 0: 2083 lakes\n",
      "    Bounds: [-153.14164553   69.15976659 -151.71727682   70.91525432]\n",
      "  Simplifying geometries...\n",
      "  Creating EE FeatureCollection...\n",
      "  FeatureCollection created successfully\n",
      "\n",
      "============================================================\n",
      "Processing Chunk 0, Year 2019\n",
      "============================================================\n",
      "  Loading full ALPOD dataset for landscape masking...\n",
      "    Found 0 total lakes in chunk region (all sizes)\n",
      "  Creating lake interior buffers and landscape rings...\n",
      "Lakes processed with geometries\n",
      "\n",
      "Processing Sentinel-1...\n",
      "  S1 processing complete\n",
      "\n",
      "Processing Sentinel-2...\n",
      "  S2 processing complete\n",
      "\n",
      "Processing ERA5 temperature...\n",
      "  Loading ERA5 hourly data for 2019...\n",
      "  Pre-computing daily means...\n",
      "  Sampling all lakes from daily means...\n",
      "  ERA5 processing complete\n",
      "\n",
      "============================================================\n",
      "TEST EXPORTS PREPARED (NOT STARTED)\n",
      "============================================================\n",
      "  S1: N/A observations ready\n",
      "  S2: N/A observations ready\n",
      "  ERA5: N/A observations ready\n",
      "\n",
      "To start exports, run the cells below.\n"
     ]
    }
   ],
   "source": [
    "# Test with one chunk and one year first\n",
    "TEST_CHUNK = 0\n",
    "TEST_YEAR = 2019\n",
    "\n",
    "print(f\"\\n{'#'*60}\")\n",
    "print(f\"TEST RUN: Chunk {TEST_CHUNK}, Year {TEST_YEAR}\")\n",
    "print(f\"{'#'*60}\")\n",
    "\n",
    "# Load chunk\n",
    "test_fc, test_gdf = load_chunk_from_bucket(TEST_CHUNK)\n",
    "test_bounds = ee.Geometry.Rectangle(test_gdf.total_bounds.tolist())\n",
    "\n",
    "# Process and export\n",
    "test_exports = export_chunk_year(TEST_CHUNK, TEST_YEAR, test_fc, test_bounds)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"TEST EXPORTS PREPARED (NOT STARTED)\")\n",
    "print(f\"{'='*60}\")\n",
    "for exp in test_exports:\n",
    "    print(f\"  {exp['type']}: {exp['count']} observations ready\")\n",
    "print(\"\\nTo start exports, run the cells below.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️  Skipping test exports (SKIP_TEST = True)\n",
      "Test exports already completed. Proceed to full export below.\n"
     ]
    }
   ],
   "source": [
    "# TEST EXPORTS\n",
    "# Use this to test the export on one chunk. Can skip it in future runs once working\n",
    "SKIP_TEST = True  #True to skip this cell. \n",
    "\n",
    "if not SKIP_TEST:\n",
    "    print(\"Starting test exports...\")\n",
    "    for exp in test_exports:\n",
    "        exp['task'].start()\n",
    "        print(f\"  Started: {exp['task'].status()['description']}\")\n",
    "    \n",
    "    print(\"\\nTest exports started! Monitor at: https://code.earthengine.google.com/tasks\")\n",
    "    print(\"\\nOnce test completes successfully, proceed to full export below.\")\n",
    "else:\n",
    "    print(\"⏭️  Skipping test exports (SKIP_TEST = True)\")\n",
    "    print(\"Test exports already completed. Proceed to full export below.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Full Export (All Chunks, All Years)\n",
    "\n",
    "**WARNING:** This will prep ~171 export tasks (19 chunks × 3 years × 3 datasets each)\n",
    "\n",
    "Only run after test export completes successfully!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing Chunk 0, Year 2019...\n",
      "  Loaded chunk 0: 2083 lakes\n",
      "    Bounds: [-153.14164553   69.15976659 -151.71727682   70.91525432]\n",
      "  Simplifying geometries...\n",
      "  Creating EE FeatureCollection...\n",
      "  FeatureCollection created successfully\n",
      "\n",
      "============================================================\n",
      "Processing Chunk 0, Year 2019\n",
      "============================================================\n",
      "  Loading full ALPOD dataset for landscape masking...\n",
      "    Found 0 total lakes in chunk region (all sizes)\n",
      "  Creating lake interior buffers and landscape rings...\n",
      "Lakes processed with geometries\n",
      "\n",
      "Processing Sentinel-1...\n",
      "  S1 processing complete\n",
      "\n",
      "Processing Sentinel-2...\n",
      "  S2 processing complete\n",
      "\n",
      "Processing ERA5 temperature...\n",
      "  Loading ERA5 hourly data for 2019...\n",
      "  Pre-computing daily means...\n",
      "  Sampling all lakes from daily means...\n",
      "  ERA5 processing complete\n",
      "\n",
      "Preparing Chunk 1, Year 2019...\n",
      "  Loaded chunk 1: 1452 lakes\n",
      "    Bounds: [-159.3747858    69.0050767  -157.84729049   70.83072285]\n",
      "  Simplifying geometries...\n",
      "  Creating EE FeatureCollection...\n",
      "  FeatureCollection created successfully\n",
      "\n",
      "============================================================\n",
      "Processing Chunk 1, Year 2019\n",
      "============================================================\n",
      "  Loading full ALPOD dataset for landscape masking...\n",
      "    Found 0 total lakes in chunk region (all sizes)\n",
      "  Creating lake interior buffers and landscape rings...\n",
      "Lakes processed with geometries\n",
      "\n",
      "Processing Sentinel-1...\n",
      "  S1 processing complete\n",
      "\n",
      "Processing Sentinel-2...\n",
      "  S2 processing complete\n",
      "\n",
      "Processing ERA5 temperature...\n",
      "  Loading ERA5 hourly data for 2019...\n",
      "  Pre-computing daily means...\n",
      "  Sampling all lakes from daily means...\n",
      "  ERA5 processing complete\n",
      "\n",
      "Preparing Chunk 2, Year 2019...\n",
      "  Loaded chunk 2: 1327 lakes\n",
      "    Bounds: [-150.35821563   69.03831436 -148.87779204   70.50265811]\n",
      "  Simplifying geometries...\n",
      "  Creating EE FeatureCollection...\n",
      "  FeatureCollection created successfully\n",
      "\n",
      "============================================================\n",
      "Processing Chunk 2, Year 2019\n",
      "============================================================\n",
      "  Loading full ALPOD dataset for landscape masking...\n",
      "    Found 0 total lakes in chunk region (all sizes)\n",
      "  Creating lake interior buffers and landscape rings...\n",
      "Lakes processed with geometries\n",
      "\n",
      "Processing Sentinel-1...\n",
      "  S1 processing complete\n",
      "\n",
      "Processing Sentinel-2...\n",
      "  S2 processing complete\n",
      "\n",
      "Processing ERA5 temperature...\n",
      "  Loading ERA5 hourly data for 2019...\n",
      "  Pre-computing daily means...\n",
      "  Sampling all lakes from daily means...\n",
      "  ERA5 processing complete\n",
      "\n",
      "Preparing Chunk 3, Year 2019...\n",
      "  Loaded chunk 3: 2518 lakes\n",
      "    Bounds: [-155.56152725   69.00417838 -154.19213543   71.11917189]\n",
      "  Simplifying geometries...\n",
      "  Creating EE FeatureCollection...\n",
      "  FeatureCollection created successfully\n",
      "\n",
      "============================================================\n",
      "Processing Chunk 3, Year 2019\n",
      "============================================================\n",
      "  Loading full ALPOD dataset for landscape masking...\n",
      "    Found 0 total lakes in chunk region (all sizes)\n",
      "  Creating lake interior buffers and landscape rings...\n",
      "Lakes processed with geometries\n",
      "\n",
      "Processing Sentinel-1...\n",
      "  S1 processing complete\n",
      "\n",
      "Processing Sentinel-2...\n",
      "  S2 processing complete\n",
      "\n",
      "Processing ERA5 temperature...\n",
      "  Loading ERA5 hourly data for 2019...\n",
      "  Pre-computing daily means...\n",
      "  Sampling all lakes from daily means...\n",
      "  ERA5 processing complete\n",
      "\n",
      "Preparing Chunk 4, Year 2019...\n",
      "  Loaded chunk 4: 780 lakes\n",
      "    Bounds: [-163.58554886   69.02430064 -160.98896853   70.29703374]\n",
      "  Simplifying geometries...\n",
      "  Creating EE FeatureCollection...\n",
      "  FeatureCollection created successfully\n",
      "\n",
      "============================================================\n",
      "Processing Chunk 4, Year 2019\n",
      "============================================================\n",
      "  Loading full ALPOD dataset for landscape masking...\n",
      "    Found 0 total lakes in chunk region (all sizes)\n",
      "  Creating lake interior buffers and landscape rings...\n",
      "Lakes processed with geometries\n",
      "\n",
      "Processing Sentinel-1...\n",
      "  S1 processing complete\n",
      "\n",
      "Processing Sentinel-2...\n",
      "  S2 processing complete\n",
      "\n",
      "Processing ERA5 temperature...\n",
      "  Loading ERA5 hourly data for 2019...\n",
      "  Pre-computing daily means...\n",
      "  Sampling all lakes from daily means...\n",
      "  ERA5 processing complete\n",
      "\n",
      "Preparing Chunk 5, Year 2019...\n",
      "  Loaded chunk 5: 223 lakes\n",
      "    Bounds: [-144.85504636   69.05870612 -141.04017085   70.12509619]\n",
      "  Simplifying geometries...\n",
      "  Creating EE FeatureCollection...\n",
      "  FeatureCollection created successfully\n",
      "\n",
      "============================================================\n",
      "Processing Chunk 5, Year 2019\n",
      "============================================================\n",
      "  Loading full ALPOD dataset for landscape masking...\n",
      "    Found 0 total lakes in chunk region (all sizes)\n",
      "  Creating lake interior buffers and landscape rings...\n",
      "Lakes processed with geometries\n",
      "\n",
      "Processing Sentinel-1...\n",
      "  S1 processing complete\n",
      "\n",
      "Processing Sentinel-2...\n",
      "  S2 processing complete\n",
      "\n",
      "Processing ERA5 temperature...\n",
      "  Loading ERA5 hourly data for 2019...\n",
      "  Pre-computing daily means...\n",
      "  Sampling all lakes from daily means...\n",
      "  ERA5 processing complete\n",
      "\n",
      "Preparing Chunk 6, Year 2019...\n",
      "  Loaded chunk 6: 1987 lakes\n",
      "    Bounds: [-157.94053561   69.01935991 -156.58982875   71.34159475]\n",
      "  Simplifying geometries...\n",
      "  Creating EE FeatureCollection...\n",
      "  FeatureCollection created successfully\n",
      "\n",
      "============================================================\n",
      "Processing Chunk 6, Year 2019\n",
      "============================================================\n",
      "  Loading full ALPOD dataset for landscape masking...\n",
      "    Found 0 total lakes in chunk region (all sizes)\n",
      "  Creating lake interior buffers and landscape rings...\n",
      "Lakes processed with geometries\n",
      "\n",
      "Processing Sentinel-1...\n",
      "  S1 processing complete\n",
      "\n",
      "Processing Sentinel-2...\n",
      "  S2 processing complete\n",
      "\n",
      "Processing ERA5 temperature...\n",
      "  Loading ERA5 hourly data for 2019...\n",
      "  Pre-computing daily means...\n",
      "  Sampling all lakes from daily means...\n",
      "  ERA5 processing complete\n",
      "\n",
      "Preparing Chunk 7, Year 2019...\n",
      "  Loaded chunk 7: 910 lakes\n",
      "    Bounds: [-149.01451562   68.99842916 -147.40284817   70.39081785]\n",
      "  Simplifying geometries...\n",
      "  Creating EE FeatureCollection...\n",
      "  FeatureCollection created successfully\n",
      "\n",
      "============================================================\n",
      "Processing Chunk 7, Year 2019\n",
      "============================================================\n",
      "  Loading full ALPOD dataset for landscape masking...\n",
      "    Found 0 total lakes in chunk region (all sizes)\n",
      "  Creating lake interior buffers and landscape rings...\n",
      "Lakes processed with geometries\n",
      "\n",
      "Processing Sentinel-1...\n",
      "  S1 processing complete\n",
      "\n",
      "Processing Sentinel-2...\n",
      "  S2 processing complete\n",
      "\n",
      "Processing ERA5 temperature...\n",
      "  Loading ERA5 hourly data for 2019...\n",
      "  Pre-computing daily means...\n",
      "  Sampling all lakes from daily means...\n",
      "  ERA5 processing complete\n",
      "\n",
      "Preparing Chunk 8, Year 2019...\n",
      "  Loaded chunk 8: 2044 lakes\n",
      "    Bounds: [-154.47142165   69.01100558 -152.894519     70.90716948]\n",
      "  Simplifying geometries...\n",
      "  Creating EE FeatureCollection...\n",
      "  FeatureCollection created successfully\n",
      "\n",
      "============================================================\n",
      "Processing Chunk 8, Year 2019\n",
      "============================================================\n",
      "  Loading full ALPOD dataset for landscape masking...\n",
      "    Found 0 total lakes in chunk region (all sizes)\n",
      "  Creating lake interior buffers and landscape rings...\n",
      "Lakes processed with geometries\n",
      "\n",
      "Processing Sentinel-1...\n",
      "  S1 processing complete\n",
      "\n",
      "Processing Sentinel-2...\n",
      "  S2 processing complete\n",
      "\n",
      "Processing ERA5 temperature...\n",
      "  Loading ERA5 hourly data for 2019...\n",
      "  Pre-computing daily means...\n",
      "  Sampling all lakes from daily means...\n",
      "  ERA5 processing complete\n",
      "\n",
      "Preparing Chunk 9, Year 2019...\n",
      "  Loaded chunk 9: 1383 lakes\n",
      "    Bounds: [-151.91050444   68.99627321 -150.23281081   70.48181719]\n",
      "  Simplifying geometries...\n",
      "  Creating EE FeatureCollection...\n",
      "  FeatureCollection created successfully\n",
      "\n",
      "============================================================\n",
      "Processing Chunk 9, Year 2019\n",
      "============================================================\n",
      "  Loading full ALPOD dataset for landscape masking...\n",
      "    Found 0 total lakes in chunk region (all sizes)\n",
      "  Creating lake interior buffers and landscape rings...\n",
      "Lakes processed with geometries\n",
      "\n",
      "Processing Sentinel-1...\n",
      "  S1 processing complete\n",
      "\n",
      "Processing Sentinel-2...\n",
      "  S2 processing complete\n",
      "\n",
      "Processing ERA5 temperature...\n",
      "  Loading ERA5 hourly data for 2019...\n",
      "  Pre-computing daily means...\n",
      "  Sampling all lakes from daily means...\n",
      "  ERA5 processing complete\n",
      "\n",
      "Preparing Chunk 10, Year 2019...\n",
      "  Loaded chunk 10: 903 lakes\n",
      "    Bounds: [-161.14428724   69.01927008 -159.31998856   70.84186196]\n",
      "  Simplifying geometries...\n",
      "  Creating EE FeatureCollection...\n",
      "  FeatureCollection created successfully\n",
      "\n",
      "============================================================\n",
      "Processing Chunk 10, Year 2019\n",
      "============================================================\n",
      "  Loading full ALPOD dataset for landscape masking...\n",
      "    Found 0 total lakes in chunk region (all sizes)\n",
      "  Creating lake interior buffers and landscape rings...\n",
      "Lakes processed with geometries\n",
      "\n",
      "Processing Sentinel-1...\n",
      "  S1 processing complete\n",
      "\n",
      "Processing Sentinel-2...\n",
      "  S2 processing complete\n",
      "\n",
      "Processing ERA5 temperature...\n",
      "  Loading ERA5 hourly data for 2019...\n",
      "  Pre-computing daily means...\n",
      "  Sampling all lakes from daily means...\n",
      "  ERA5 processing complete\n",
      "\n",
      "Preparing Chunk 11, Year 2019...\n",
      "  Loaded chunk 11: 2148 lakes\n",
      "    Bounds: [-156.6423802    69.29765798 -155.37970823   71.36189668]\n",
      "  Simplifying geometries...\n",
      "  Creating EE FeatureCollection...\n",
      "  FeatureCollection created successfully\n",
      "\n",
      "============================================================\n",
      "Processing Chunk 11, Year 2019\n",
      "============================================================\n",
      "  Loading full ALPOD dataset for landscape masking...\n",
      "    Found 0 total lakes in chunk region (all sizes)\n",
      "  Creating lake interior buffers and landscape rings...\n",
      "Lakes processed with geometries\n",
      "\n",
      "Processing Sentinel-1...\n",
      "  S1 processing complete\n",
      "\n",
      "Processing Sentinel-2...\n",
      "  S2 processing complete\n",
      "\n",
      "Processing ERA5 temperature...\n",
      "  Loading ERA5 hourly data for 2019...\n",
      "  Pre-computing daily means...\n",
      "  Sampling all lakes from daily means...\n",
      "  ERA5 processing complete\n",
      "\n",
      "Preparing Chunk 12, Year 2019...\n",
      "  Loaded chunk 12: 452 lakes\n",
      "    Bounds: [-147.41524492   69.03463127 -144.89969263   70.18645113]\n",
      "  Simplifying geometries...\n",
      "  Creating EE FeatureCollection...\n",
      "  FeatureCollection created successfully\n",
      "\n",
      "============================================================\n",
      "Processing Chunk 12, Year 2019\n",
      "============================================================\n",
      "  Loading full ALPOD dataset for landscape masking...\n",
      "    Found 0 total lakes in chunk region (all sizes)\n",
      "  Creating lake interior buffers and landscape rings...\n",
      "Lakes processed with geometries\n",
      "\n",
      "Processing Sentinel-1...\n",
      "  S1 processing complete\n",
      "\n",
      "Processing Sentinel-2...\n",
      "  S2 processing complete\n",
      "\n",
      "Processing ERA5 temperature...\n",
      "  Loading ERA5 hourly data for 2019...\n",
      "  Pre-computing daily means...\n",
      "  Sampling all lakes from daily means...\n",
      "  ERA5 processing complete\n",
      "\n",
      "Preparing Chunk 0, Year 2020...\n",
      "  Loaded chunk 0: 2083 lakes\n",
      "    Bounds: [-153.14164553   69.15976659 -151.71727682   70.91525432]\n",
      "  Simplifying geometries...\n",
      "  Creating EE FeatureCollection...\n",
      "  FeatureCollection created successfully\n",
      "\n",
      "============================================================\n",
      "Processing Chunk 0, Year 2020\n",
      "============================================================\n",
      "  Loading full ALPOD dataset for landscape masking...\n",
      "    Found 0 total lakes in chunk region (all sizes)\n",
      "  Creating lake interior buffers and landscape rings...\n",
      "Lakes processed with geometries\n",
      "\n",
      "Processing Sentinel-1...\n",
      "  S1 processing complete\n",
      "\n",
      "Processing Sentinel-2...\n",
      "  S2 processing complete\n",
      "\n",
      "Processing ERA5 temperature...\n",
      "  Loading ERA5 hourly data for 2020...\n",
      "  Pre-computing daily means...\n",
      "  Sampling all lakes from daily means...\n",
      "  ERA5 processing complete\n",
      "\n",
      "Preparing Chunk 1, Year 2020...\n",
      "  Loaded chunk 1: 1452 lakes\n",
      "    Bounds: [-159.3747858    69.0050767  -157.84729049   70.83072285]\n",
      "  Simplifying geometries...\n",
      "  Creating EE FeatureCollection...\n",
      "  FeatureCollection created successfully\n",
      "\n",
      "============================================================\n",
      "Processing Chunk 1, Year 2020\n",
      "============================================================\n",
      "  Loading full ALPOD dataset for landscape masking...\n",
      "    Found 0 total lakes in chunk region (all sizes)\n",
      "  Creating lake interior buffers and landscape rings...\n",
      "Lakes processed with geometries\n",
      "\n",
      "Processing Sentinel-1...\n",
      "  S1 processing complete\n",
      "\n",
      "Processing Sentinel-2...\n",
      "  S2 processing complete\n",
      "\n",
      "Processing ERA5 temperature...\n",
      "  Loading ERA5 hourly data for 2020...\n",
      "  Pre-computing daily means...\n",
      "  Sampling all lakes from daily means...\n",
      "  ERA5 processing complete\n",
      "\n",
      "Preparing Chunk 2, Year 2020...\n",
      "  Loaded chunk 2: 1327 lakes\n",
      "    Bounds: [-150.35821563   69.03831436 -148.87779204   70.50265811]\n",
      "  Simplifying geometries...\n",
      "  Creating EE FeatureCollection...\n",
      "  FeatureCollection created successfully\n",
      "\n",
      "============================================================\n",
      "Processing Chunk 2, Year 2020\n",
      "============================================================\n",
      "  Loading full ALPOD dataset for landscape masking...\n",
      "    Found 0 total lakes in chunk region (all sizes)\n",
      "  Creating lake interior buffers and landscape rings...\n",
      "Lakes processed with geometries\n",
      "\n",
      "Processing Sentinel-1...\n",
      "  S1 processing complete\n",
      "\n",
      "Processing Sentinel-2...\n",
      "  S2 processing complete\n",
      "\n",
      "Processing ERA5 temperature...\n",
      "  Loading ERA5 hourly data for 2020...\n",
      "  Pre-computing daily means...\n",
      "  Sampling all lakes from daily means...\n",
      "  ERA5 processing complete\n",
      "\n",
      "Preparing Chunk 3, Year 2020...\n",
      "  Loaded chunk 3: 2518 lakes\n",
      "    Bounds: [-155.56152725   69.00417838 -154.19213543   71.11917189]\n",
      "  Simplifying geometries...\n",
      "  Creating EE FeatureCollection...\n",
      "  FeatureCollection created successfully\n",
      "\n",
      "============================================================\n",
      "Processing Chunk 3, Year 2020\n",
      "============================================================\n",
      "  Loading full ALPOD dataset for landscape masking...\n",
      "    Found 0 total lakes in chunk region (all sizes)\n",
      "  Creating lake interior buffers and landscape rings...\n",
      "Lakes processed with geometries\n",
      "\n",
      "Processing Sentinel-1...\n",
      "  S1 processing complete\n",
      "\n",
      "Processing Sentinel-2...\n",
      "  S2 processing complete\n",
      "\n",
      "Processing ERA5 temperature...\n",
      "  Loading ERA5 hourly data for 2020...\n",
      "  Pre-computing daily means...\n",
      "  Sampling all lakes from daily means...\n",
      "  ERA5 processing complete\n",
      "\n",
      "Preparing Chunk 4, Year 2020...\n",
      "  Loaded chunk 4: 780 lakes\n",
      "    Bounds: [-163.58554886   69.02430064 -160.98896853   70.29703374]\n",
      "  Simplifying geometries...\n",
      "  Creating EE FeatureCollection...\n",
      "  FeatureCollection created successfully\n",
      "\n",
      "============================================================\n",
      "Processing Chunk 4, Year 2020\n",
      "============================================================\n",
      "  Loading full ALPOD dataset for landscape masking...\n",
      "    Found 0 total lakes in chunk region (all sizes)\n",
      "  Creating lake interior buffers and landscape rings...\n",
      "Lakes processed with geometries\n",
      "\n",
      "Processing Sentinel-1...\n",
      "  S1 processing complete\n",
      "\n",
      "Processing Sentinel-2...\n",
      "  S2 processing complete\n",
      "\n",
      "Processing ERA5 temperature...\n",
      "  Loading ERA5 hourly data for 2020...\n",
      "  Pre-computing daily means...\n",
      "  Sampling all lakes from daily means...\n",
      "  ERA5 processing complete\n",
      "\n",
      "Preparing Chunk 5, Year 2020...\n",
      "  Loaded chunk 5: 223 lakes\n",
      "    Bounds: [-144.85504636   69.05870612 -141.04017085   70.12509619]\n",
      "  Simplifying geometries...\n",
      "  Creating EE FeatureCollection...\n",
      "  FeatureCollection created successfully\n",
      "\n",
      "============================================================\n",
      "Processing Chunk 5, Year 2020\n",
      "============================================================\n",
      "  Loading full ALPOD dataset for landscape masking...\n",
      "    Found 0 total lakes in chunk region (all sizes)\n",
      "  Creating lake interior buffers and landscape rings...\n",
      "Lakes processed with geometries\n",
      "\n",
      "Processing Sentinel-1...\n",
      "  S1 processing complete\n",
      "\n",
      "Processing Sentinel-2...\n",
      "  S2 processing complete\n",
      "\n",
      "Processing ERA5 temperature...\n",
      "  Loading ERA5 hourly data for 2020...\n",
      "  Pre-computing daily means...\n",
      "  Sampling all lakes from daily means...\n",
      "  ERA5 processing complete\n",
      "\n",
      "Preparing Chunk 6, Year 2020...\n",
      "  Loaded chunk 6: 1987 lakes\n",
      "    Bounds: [-157.94053561   69.01935991 -156.58982875   71.34159475]\n",
      "  Simplifying geometries...\n",
      "  Creating EE FeatureCollection...\n",
      "  FeatureCollection created successfully\n",
      "\n",
      "============================================================\n",
      "Processing Chunk 6, Year 2020\n",
      "============================================================\n",
      "  Loading full ALPOD dataset for landscape masking...\n",
      "    Found 0 total lakes in chunk region (all sizes)\n",
      "  Creating lake interior buffers and landscape rings...\n",
      "Lakes processed with geometries\n",
      "\n",
      "Processing Sentinel-1...\n",
      "  S1 processing complete\n",
      "\n",
      "Processing Sentinel-2...\n",
      "  S2 processing complete\n",
      "\n",
      "Processing ERA5 temperature...\n",
      "  Loading ERA5 hourly data for 2020...\n",
      "  Pre-computing daily means...\n",
      "  Sampling all lakes from daily means...\n",
      "  ERA5 processing complete\n",
      "\n",
      "Preparing Chunk 7, Year 2020...\n",
      "  Loaded chunk 7: 910 lakes\n",
      "    Bounds: [-149.01451562   68.99842916 -147.40284817   70.39081785]\n",
      "  Simplifying geometries...\n",
      "  Creating EE FeatureCollection...\n",
      "  FeatureCollection created successfully\n",
      "\n",
      "============================================================\n",
      "Processing Chunk 7, Year 2020\n",
      "============================================================\n",
      "  Loading full ALPOD dataset for landscape masking...\n",
      "    Found 0 total lakes in chunk region (all sizes)\n",
      "  Creating lake interior buffers and landscape rings...\n",
      "Lakes processed with geometries\n",
      "\n",
      "Processing Sentinel-1...\n",
      "  S1 processing complete\n",
      "\n",
      "Processing Sentinel-2...\n",
      "  S2 processing complete\n",
      "\n",
      "Processing ERA5 temperature...\n",
      "  Loading ERA5 hourly data for 2020...\n",
      "  Pre-computing daily means...\n",
      "  Sampling all lakes from daily means...\n",
      "  ERA5 processing complete\n",
      "\n",
      "Preparing Chunk 8, Year 2020...\n",
      "  Loaded chunk 8: 2044 lakes\n",
      "    Bounds: [-154.47142165   69.01100558 -152.894519     70.90716948]\n",
      "  Simplifying geometries...\n",
      "  Creating EE FeatureCollection...\n",
      "  FeatureCollection created successfully\n",
      "\n",
      "============================================================\n",
      "Processing Chunk 8, Year 2020\n",
      "============================================================\n",
      "  Loading full ALPOD dataset for landscape masking...\n",
      "    Found 0 total lakes in chunk region (all sizes)\n",
      "  Creating lake interior buffers and landscape rings...\n",
      "Lakes processed with geometries\n",
      "\n",
      "Processing Sentinel-1...\n",
      "  S1 processing complete\n",
      "\n",
      "Processing Sentinel-2...\n",
      "  S2 processing complete\n",
      "\n",
      "Processing ERA5 temperature...\n",
      "  Loading ERA5 hourly data for 2020...\n",
      "  Pre-computing daily means...\n",
      "  Sampling all lakes from daily means...\n",
      "  ERA5 processing complete\n",
      "\n",
      "Preparing Chunk 9, Year 2020...\n",
      "  Loaded chunk 9: 1383 lakes\n",
      "    Bounds: [-151.91050444   68.99627321 -150.23281081   70.48181719]\n",
      "  Simplifying geometries...\n",
      "  Creating EE FeatureCollection...\n",
      "  FeatureCollection created successfully\n",
      "\n",
      "============================================================\n",
      "Processing Chunk 9, Year 2020\n",
      "============================================================\n",
      "  Loading full ALPOD dataset for landscape masking...\n",
      "    Found 0 total lakes in chunk region (all sizes)\n",
      "  Creating lake interior buffers and landscape rings...\n",
      "Lakes processed with geometries\n",
      "\n",
      "Processing Sentinel-1...\n",
      "  S1 processing complete\n",
      "\n",
      "Processing Sentinel-2...\n",
      "  S2 processing complete\n",
      "\n",
      "Processing ERA5 temperature...\n",
      "  Loading ERA5 hourly data for 2020...\n",
      "  Pre-computing daily means...\n",
      "  Sampling all lakes from daily means...\n",
      "  ERA5 processing complete\n",
      "\n",
      "Preparing Chunk 10, Year 2020...\n",
      "  Loaded chunk 10: 903 lakes\n",
      "    Bounds: [-161.14428724   69.01927008 -159.31998856   70.84186196]\n",
      "  Simplifying geometries...\n",
      "  Creating EE FeatureCollection...\n",
      "  FeatureCollection created successfully\n",
      "\n",
      "============================================================\n",
      "Processing Chunk 10, Year 2020\n",
      "============================================================\n",
      "  Loading full ALPOD dataset for landscape masking...\n",
      "    Found 0 total lakes in chunk region (all sizes)\n",
      "  Creating lake interior buffers and landscape rings...\n",
      "Lakes processed with geometries\n",
      "\n",
      "Processing Sentinel-1...\n",
      "  S1 processing complete\n",
      "\n",
      "Processing Sentinel-2...\n",
      "  S2 processing complete\n",
      "\n",
      "Processing ERA5 temperature...\n",
      "  Loading ERA5 hourly data for 2020...\n",
      "  Pre-computing daily means...\n",
      "  Sampling all lakes from daily means...\n",
      "  ERA5 processing complete\n",
      "\n",
      "Preparing Chunk 11, Year 2020...\n",
      "  Loaded chunk 11: 2148 lakes\n",
      "    Bounds: [-156.6423802    69.29765798 -155.37970823   71.36189668]\n",
      "  Simplifying geometries...\n",
      "  Creating EE FeatureCollection...\n",
      "  FeatureCollection created successfully\n",
      "\n",
      "============================================================\n",
      "Processing Chunk 11, Year 2020\n",
      "============================================================\n",
      "  Loading full ALPOD dataset for landscape masking...\n",
      "    Found 0 total lakes in chunk region (all sizes)\n",
      "  Creating lake interior buffers and landscape rings...\n",
      "Lakes processed with geometries\n",
      "\n",
      "Processing Sentinel-1...\n",
      "  S1 processing complete\n",
      "\n",
      "Processing Sentinel-2...\n",
      "  S2 processing complete\n",
      "\n",
      "Processing ERA5 temperature...\n",
      "  Loading ERA5 hourly data for 2020...\n",
      "  Pre-computing daily means...\n",
      "  Sampling all lakes from daily means...\n",
      "  ERA5 processing complete\n",
      "\n",
      "Preparing Chunk 12, Year 2020...\n",
      "  Loaded chunk 12: 452 lakes\n",
      "    Bounds: [-147.41524492   69.03463127 -144.89969263   70.18645113]\n",
      "  Simplifying geometries...\n",
      "  Creating EE FeatureCollection...\n",
      "  FeatureCollection created successfully\n",
      "\n",
      "============================================================\n",
      "Processing Chunk 12, Year 2020\n",
      "============================================================\n",
      "  Loading full ALPOD dataset for landscape masking...\n",
      "    Found 0 total lakes in chunk region (all sizes)\n",
      "  Creating lake interior buffers and landscape rings...\n",
      "Lakes processed with geometries\n",
      "\n",
      "Processing Sentinel-1...\n",
      "  S1 processing complete\n",
      "\n",
      "Processing Sentinel-2...\n",
      "  S2 processing complete\n",
      "\n",
      "Processing ERA5 temperature...\n",
      "  Loading ERA5 hourly data for 2020...\n",
      "  Pre-computing daily means...\n",
      "  Sampling all lakes from daily means...\n",
      "  ERA5 processing complete\n",
      "\n",
      "Preparing Chunk 0, Year 2021...\n",
      "  Loaded chunk 0: 2083 lakes\n",
      "    Bounds: [-153.14164553   69.15976659 -151.71727682   70.91525432]\n",
      "  Simplifying geometries...\n",
      "  Creating EE FeatureCollection...\n",
      "  FeatureCollection created successfully\n",
      "\n",
      "============================================================\n",
      "Processing Chunk 0, Year 2021\n",
      "============================================================\n",
      "  Loading full ALPOD dataset for landscape masking...\n",
      "    Found 0 total lakes in chunk region (all sizes)\n",
      "  Creating lake interior buffers and landscape rings...\n",
      "Lakes processed with geometries\n",
      "\n",
      "Processing Sentinel-1...\n",
      "  S1 processing complete\n",
      "\n",
      "Processing Sentinel-2...\n",
      "  S2 processing complete\n",
      "\n",
      "Processing ERA5 temperature...\n",
      "  Loading ERA5 hourly data for 2021...\n",
      "  Pre-computing daily means...\n",
      "  Sampling all lakes from daily means...\n",
      "  ERA5 processing complete\n",
      "\n",
      "Preparing Chunk 1, Year 2021...\n",
      "  Loaded chunk 1: 1452 lakes\n",
      "    Bounds: [-159.3747858    69.0050767  -157.84729049   70.83072285]\n",
      "  Simplifying geometries...\n",
      "  Creating EE FeatureCollection...\n",
      "  FeatureCollection created successfully\n",
      "\n",
      "============================================================\n",
      "Processing Chunk 1, Year 2021\n",
      "============================================================\n",
      "  Loading full ALPOD dataset for landscape masking...\n",
      "    Found 0 total lakes in chunk region (all sizes)\n",
      "  Creating lake interior buffers and landscape rings...\n",
      "Lakes processed with geometries\n",
      "\n",
      "Processing Sentinel-1...\n",
      "  S1 processing complete\n",
      "\n",
      "Processing Sentinel-2...\n",
      "  S2 processing complete\n",
      "\n",
      "Processing ERA5 temperature...\n",
      "  Loading ERA5 hourly data for 2021...\n",
      "  Pre-computing daily means...\n",
      "  Sampling all lakes from daily means...\n",
      "  ERA5 processing complete\n",
      "\n",
      "Preparing Chunk 2, Year 2021...\n",
      "  Loaded chunk 2: 1327 lakes\n",
      "    Bounds: [-150.35821563   69.03831436 -148.87779204   70.50265811]\n",
      "  Simplifying geometries...\n",
      "  Creating EE FeatureCollection...\n",
      "  FeatureCollection created successfully\n",
      "\n",
      "============================================================\n",
      "Processing Chunk 2, Year 2021\n",
      "============================================================\n",
      "  Loading full ALPOD dataset for landscape masking...\n",
      "    Found 0 total lakes in chunk region (all sizes)\n",
      "  Creating lake interior buffers and landscape rings...\n",
      "Lakes processed with geometries\n",
      "\n",
      "Processing Sentinel-1...\n",
      "  S1 processing complete\n",
      "\n",
      "Processing Sentinel-2...\n",
      "  S2 processing complete\n",
      "\n",
      "Processing ERA5 temperature...\n",
      "  Loading ERA5 hourly data for 2021...\n",
      "  Pre-computing daily means...\n",
      "  Sampling all lakes from daily means...\n",
      "  ERA5 processing complete\n",
      "\n",
      "Preparing Chunk 3, Year 2021...\n",
      "  Loaded chunk 3: 2518 lakes\n",
      "    Bounds: [-155.56152725   69.00417838 -154.19213543   71.11917189]\n",
      "  Simplifying geometries...\n",
      "  Creating EE FeatureCollection...\n",
      "  FeatureCollection created successfully\n",
      "\n",
      "============================================================\n",
      "Processing Chunk 3, Year 2021\n",
      "============================================================\n",
      "  Loading full ALPOD dataset for landscape masking...\n",
      "    Found 0 total lakes in chunk region (all sizes)\n",
      "  Creating lake interior buffers and landscape rings...\n",
      "Lakes processed with geometries\n",
      "\n",
      "Processing Sentinel-1...\n",
      "  S1 processing complete\n",
      "\n",
      "Processing Sentinel-2...\n",
      "  S2 processing complete\n",
      "\n",
      "Processing ERA5 temperature...\n",
      "  Loading ERA5 hourly data for 2021...\n",
      "  Pre-computing daily means...\n",
      "  Sampling all lakes from daily means...\n",
      "  ERA5 processing complete\n",
      "\n",
      "Preparing Chunk 4, Year 2021...\n",
      "  Loaded chunk 4: 780 lakes\n",
      "    Bounds: [-163.58554886   69.02430064 -160.98896853   70.29703374]\n",
      "  Simplifying geometries...\n",
      "  Creating EE FeatureCollection...\n",
      "  FeatureCollection created successfully\n",
      "\n",
      "============================================================\n",
      "Processing Chunk 4, Year 2021\n",
      "============================================================\n",
      "  Loading full ALPOD dataset for landscape masking...\n",
      "    Found 0 total lakes in chunk region (all sizes)\n",
      "  Creating lake interior buffers and landscape rings...\n",
      "Lakes processed with geometries\n",
      "\n",
      "Processing Sentinel-1...\n",
      "  S1 processing complete\n",
      "\n",
      "Processing Sentinel-2...\n",
      "  S2 processing complete\n",
      "\n",
      "Processing ERA5 temperature...\n",
      "  Loading ERA5 hourly data for 2021...\n",
      "  Pre-computing daily means...\n",
      "  Sampling all lakes from daily means...\n",
      "  ERA5 processing complete\n",
      "\n",
      "Preparing Chunk 5, Year 2021...\n",
      "  Loaded chunk 5: 223 lakes\n",
      "    Bounds: [-144.85504636   69.05870612 -141.04017085   70.12509619]\n",
      "  Simplifying geometries...\n",
      "  Creating EE FeatureCollection...\n",
      "  FeatureCollection created successfully\n",
      "\n",
      "============================================================\n",
      "Processing Chunk 5, Year 2021\n",
      "============================================================\n",
      "  Loading full ALPOD dataset for landscape masking...\n",
      "    Found 0 total lakes in chunk region (all sizes)\n",
      "  Creating lake interior buffers and landscape rings...\n",
      "Lakes processed with geometries\n",
      "\n",
      "Processing Sentinel-1...\n",
      "  S1 processing complete\n",
      "\n",
      "Processing Sentinel-2...\n",
      "  S2 processing complete\n",
      "\n",
      "Processing ERA5 temperature...\n",
      "  Loading ERA5 hourly data for 2021...\n",
      "  Pre-computing daily means...\n",
      "  Sampling all lakes from daily means...\n",
      "  ERA5 processing complete\n",
      "\n",
      "Preparing Chunk 6, Year 2021...\n",
      "  Loaded chunk 6: 1987 lakes\n",
      "    Bounds: [-157.94053561   69.01935991 -156.58982875   71.34159475]\n",
      "  Simplifying geometries...\n",
      "  Creating EE FeatureCollection...\n",
      "  FeatureCollection created successfully\n",
      "\n",
      "============================================================\n",
      "Processing Chunk 6, Year 2021\n",
      "============================================================\n",
      "  Loading full ALPOD dataset for landscape masking...\n",
      "    Found 0 total lakes in chunk region (all sizes)\n",
      "  Creating lake interior buffers and landscape rings...\n",
      "Lakes processed with geometries\n",
      "\n",
      "Processing Sentinel-1...\n",
      "  S1 processing complete\n",
      "\n",
      "Processing Sentinel-2...\n",
      "  S2 processing complete\n",
      "\n",
      "Processing ERA5 temperature...\n",
      "  Loading ERA5 hourly data for 2021...\n",
      "  Pre-computing daily means...\n",
      "  Sampling all lakes from daily means...\n",
      "  ERA5 processing complete\n",
      "\n",
      "Preparing Chunk 7, Year 2021...\n",
      "  Loaded chunk 7: 910 lakes\n",
      "    Bounds: [-149.01451562   68.99842916 -147.40284817   70.39081785]\n",
      "  Simplifying geometries...\n",
      "  Creating EE FeatureCollection...\n",
      "  FeatureCollection created successfully\n",
      "\n",
      "============================================================\n",
      "Processing Chunk 7, Year 2021\n",
      "============================================================\n",
      "  Loading full ALPOD dataset for landscape masking...\n",
      "    Found 0 total lakes in chunk region (all sizes)\n",
      "  Creating lake interior buffers and landscape rings...\n",
      "Lakes processed with geometries\n",
      "\n",
      "Processing Sentinel-1...\n",
      "  S1 processing complete\n",
      "\n",
      "Processing Sentinel-2...\n",
      "  S2 processing complete\n",
      "\n",
      "Processing ERA5 temperature...\n",
      "  Loading ERA5 hourly data for 2021...\n",
      "  Pre-computing daily means...\n",
      "  Sampling all lakes from daily means...\n",
      "  ERA5 processing complete\n",
      "\n",
      "Preparing Chunk 8, Year 2021...\n",
      "  Loaded chunk 8: 2044 lakes\n",
      "    Bounds: [-154.47142165   69.01100558 -152.894519     70.90716948]\n",
      "  Simplifying geometries...\n",
      "  Creating EE FeatureCollection...\n",
      "  FeatureCollection created successfully\n",
      "\n",
      "============================================================\n",
      "Processing Chunk 8, Year 2021\n",
      "============================================================\n",
      "  Loading full ALPOD dataset for landscape masking...\n",
      "    Found 0 total lakes in chunk region (all sizes)\n",
      "  Creating lake interior buffers and landscape rings...\n",
      "Lakes processed with geometries\n",
      "\n",
      "Processing Sentinel-1...\n",
      "  S1 processing complete\n",
      "\n",
      "Processing Sentinel-2...\n",
      "  S2 processing complete\n",
      "\n",
      "Processing ERA5 temperature...\n",
      "  Loading ERA5 hourly data for 2021...\n",
      "  Pre-computing daily means...\n",
      "  Sampling all lakes from daily means...\n",
      "  ERA5 processing complete\n",
      "\n",
      "Preparing Chunk 9, Year 2021...\n",
      "  Loaded chunk 9: 1383 lakes\n",
      "    Bounds: [-151.91050444   68.99627321 -150.23281081   70.48181719]\n",
      "  Simplifying geometries...\n",
      "  Creating EE FeatureCollection...\n",
      "  FeatureCollection created successfully\n",
      "\n",
      "============================================================\n",
      "Processing Chunk 9, Year 2021\n",
      "============================================================\n",
      "  Loading full ALPOD dataset for landscape masking...\n",
      "    Found 0 total lakes in chunk region (all sizes)\n",
      "  Creating lake interior buffers and landscape rings...\n",
      "Lakes processed with geometries\n",
      "\n",
      "Processing Sentinel-1...\n",
      "  S1 processing complete\n",
      "\n",
      "Processing Sentinel-2...\n",
      "  S2 processing complete\n",
      "\n",
      "Processing ERA5 temperature...\n",
      "  Loading ERA5 hourly data for 2021...\n",
      "  Pre-computing daily means...\n",
      "  Sampling all lakes from daily means...\n",
      "  ERA5 processing complete\n",
      "\n",
      "Preparing Chunk 10, Year 2021...\n",
      "  Loaded chunk 10: 903 lakes\n",
      "    Bounds: [-161.14428724   69.01927008 -159.31998856   70.84186196]\n",
      "  Simplifying geometries...\n",
      "  Creating EE FeatureCollection...\n",
      "  FeatureCollection created successfully\n",
      "\n",
      "============================================================\n",
      "Processing Chunk 10, Year 2021\n",
      "============================================================\n",
      "  Loading full ALPOD dataset for landscape masking...\n",
      "    Found 0 total lakes in chunk region (all sizes)\n",
      "  Creating lake interior buffers and landscape rings...\n",
      "Lakes processed with geometries\n",
      "\n",
      "Processing Sentinel-1...\n",
      "  S1 processing complete\n",
      "\n",
      "Processing Sentinel-2...\n",
      "  S2 processing complete\n",
      "\n",
      "Processing ERA5 temperature...\n",
      "  Loading ERA5 hourly data for 2021...\n",
      "  Pre-computing daily means...\n",
      "  Sampling all lakes from daily means...\n",
      "  ERA5 processing complete\n",
      "\n",
      "Preparing Chunk 11, Year 2021...\n",
      "  Loaded chunk 11: 2148 lakes\n",
      "    Bounds: [-156.6423802    69.29765798 -155.37970823   71.36189668]\n",
      "  Simplifying geometries...\n",
      "  Creating EE FeatureCollection...\n",
      "  FeatureCollection created successfully\n",
      "\n",
      "============================================================\n",
      "Processing Chunk 11, Year 2021\n",
      "============================================================\n",
      "  Loading full ALPOD dataset for landscape masking...\n",
      "    Found 0 total lakes in chunk region (all sizes)\n",
      "  Creating lake interior buffers and landscape rings...\n",
      "Lakes processed with geometries\n",
      "\n",
      "Processing Sentinel-1...\n",
      "  S1 processing complete\n",
      "\n",
      "Processing Sentinel-2...\n",
      "  S2 processing complete\n",
      "\n",
      "Processing ERA5 temperature...\n",
      "  Loading ERA5 hourly data for 2021...\n",
      "  Pre-computing daily means...\n",
      "  Sampling all lakes from daily means...\n",
      "  ERA5 processing complete\n",
      "\n",
      "Preparing Chunk 12, Year 2021...\n",
      "  Loaded chunk 12: 452 lakes\n",
      "    Bounds: [-147.41524492   69.03463127 -144.89969263   70.18645113]\n",
      "  Simplifying geometries...\n",
      "  Creating EE FeatureCollection...\n",
      "  FeatureCollection created successfully\n",
      "\n",
      "============================================================\n",
      "Processing Chunk 12, Year 2021\n",
      "============================================================\n",
      "  Loading full ALPOD dataset for landscape masking...\n",
      "    Found 0 total lakes in chunk region (all sizes)\n",
      "  Creating lake interior buffers and landscape rings...\n",
      "Lakes processed with geometries\n",
      "\n",
      "Processing Sentinel-1...\n",
      "  S1 processing complete\n",
      "\n",
      "Processing Sentinel-2...\n",
      "  S2 processing complete\n",
      "\n",
      "Processing ERA5 temperature...\n",
      "  Loading ERA5 hourly data for 2021...\n",
      "  Pre-computing daily means...\n",
      "  Sampling all lakes from daily means...\n",
      "  ERA5 processing complete\n",
      "\n",
      "============================================================\n",
      "ALL EXPORTS PREPARED: 117 tasks\n",
      "============================================================\n",
      "\n",
      "Ready to start. Run next cell to begin all exports.\n"
     ]
    }
   ],
   "source": [
    "# Prepare all exports (run once test is good)\n",
    "all_exports = []\n",
    "\n",
    "for year in YEARS:\n",
    "    for chunk_id in range(n_chunks):\n",
    "        print(f\"\\nPreparing Chunk {chunk_id}, Year {year}...\")\n",
    "        \n",
    "        # Load chunk\n",
    "        chunk_fc, chunk_gdf = load_chunk_from_bucket(chunk_id)\n",
    "        chunk_bounds = ee.Geometry.Rectangle(chunk_gdf.total_bounds.tolist())\n",
    "        \n",
    "        # Prepare exports\n",
    "        exports = export_chunk_year(chunk_id, year, chunk_fc, chunk_bounds)\n",
    "        \n",
    "        for exp in exports:\n",
    "            all_exports.append({\n",
    "                'chunk_id': chunk_id,\n",
    "                'year': year,\n",
    "                'type': exp['type'],\n",
    "                'task': exp['task'],\n",
    "                'count': exp['count']\n",
    "            })\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"ALL EXPORTS PREPARED: {len(all_exports)} tasks\")\n",
    "print(f\"{'='*60}\")\n",
    "print(\"\\nReady to start. Run next cell to begin all exports.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 117 export tasks...\n",
      "This may take a few minutes to submit all tasks.\n",
      "\n",
      "  Started 10/117 tasks...\n",
      "  Started 20/117 tasks...\n",
      "  Started 30/117 tasks...\n",
      "  Started 40/117 tasks...\n",
      "  Started 50/117 tasks...\n",
      "  Started 60/117 tasks...\n",
      "  Started 70/117 tasks...\n",
      "  Started 80/117 tasks...\n",
      "  Started 90/117 tasks...\n",
      "  Started 100/117 tasks...\n",
      "  Started 110/117 tasks...\n",
      "\n",
      "============================================================\n",
      "ALL 117 EXPORTS STARTED!\n",
      "============================================================\n",
      "\n",
      "Monitor progress at: https://code.earthengine.google.com/tasks\n",
      "\n",
      "Outputs will be in: gs://wustl-eeps-geospatial/thermokarst_lakes/exports/YEAR/chunk_XX/\n"
     ]
    }
   ],
   "source": [
    "# START ALL EXPORTS\n",
    "# Only run after one-chunk works!\n",
    "\n",
    "print(f\"Starting {len(all_exports)} export tasks...\")\n",
    "print(\"This may take a few minutes to submit all tasks.\\n\")\n",
    "\n",
    "for i, exp in enumerate(all_exports):\n",
    "    exp['task'].start()\n",
    "    \n",
    "    if (i+1) % 10 == 0:\n",
    "        print(f\"  Started {i+1}/{len(all_exports)} tasks...\")\n",
    "        time.sleep(2)  # Brief pause to avoid overwhelming GEE\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"ALL {len(all_exports)} EXPORTS STARTED!\")\n",
    "print(f\"{'='*60}\")\n",
    "print(\"\\nMonitor progress at: https://code.earthengine.google.com/tasks\")\n",
    "print(f\"\\nOutputs will be in: gs://{BUCKET}/{OUTPUT_PATH}/YEAR/chunk_XX/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Monitor Export Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check status of all exports\n",
    "def check_export_status():\n",
    "    status_summary = {\n",
    "        'READY': 0,\n",
    "        'RUNNING': 0,\n",
    "        'COMPLETED': 0,\n",
    "        'FAILED': 0,\n",
    "        'CANCELLED': 0\n",
    "    }\n",
    "    \n",
    "    for exp in all_exports:\n",
    "        status = exp['task'].status()['state']\n",
    "        status_summary[status] = status_summary.get(status, 0) + 1\n",
    "    \n",
    "    print(f\"Export Status Summary:\")\n",
    "    print(f\"  Total tasks: {len(all_exports)}\")\n",
    "    for state, count in status_summary.items():\n",
    "        if count > 0:\n",
    "            print(f\"    {state}: {count}\")\n",
    "    \n",
    "    return status_summary\n",
    "\n",
    "# Run this cell periodically to check progress\n",
    "check_export_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "This notebook exports:\n",
    "- **Sentinel-1**: VV/VH backscatter for each lake interior\n",
    "- **Sentinel-2**: NDSI-based ice fraction (with cloud filtering)\n",
    "- **ERA5**: Daily mean temperature at lake locations\n",
    "\n",
    "**For:**\n",
    "- ~19 spatial chunks\n",
    "- 3 years (2019, 2020, 2021)\n",
    "- ~28,000 North Slope lakes\n",
    "\n",
    "**Output structure:**\n",
    "```\n",
    "gs://wustl-eeps-geospatial/thermokarst_lakes/exports/\n",
    "├── 2019/\n",
    "│   ├── chunk_00/\n",
    "│   │   ├── s1_data.csv\n",
    "│   │   ├── s2_data.csv\n",
    "│   │   └── era5_data.csv\n",
    "│   ├── chunk_01/\n",
    "│   └── ...\n",
    "├── 2020/\n",
    "└── 2021/\n",
    "```\n",
    "\n",
    "**Next step:** Combine CSVs and run ice detection algorithm (Notebook 03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "gee",
   "name": "workbench-notebooks.m134",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m134"
  },
  "kernelspec": {
   "display_name": "GEE Geospatial (Local)",
   "language": "python",
   "name": "gee"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
